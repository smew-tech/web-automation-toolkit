#!/usr/bin/env python3
"""
Web Automation Workflow Worker
H·ªá th·ªëng worker linh ho·∫°t ƒë·ªÉ th·ª±c thi c√°c workflow t·ª± ƒë·ªông h√≥a web
s·ª≠ d·ª•ng Strategy Pattern v√† State Pattern v·ªõi Playwright.
"""

import asyncio
import argparse
import sys
from pathlib import Path
from core.workflow_manager import WorkflowManager

# Proxy settings m·∫´u
SAMPLE_PROXY_SETTINGS = {
    "server": "http://proxy.example.com:8080",
    "username": "proxy_user",
    "password": "proxy_pass"
}

async def main():
    """Entry point ch√≠nh c·ªßa ·ª©ng d·ª•ng."""
    parser = argparse.ArgumentParser(
        description="Web Automation Workflow Worker",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
V√≠ d·ª• s·ª≠ d·ª•ng:
  python main.py --load-dir workflows_json --run-all
  python main.py --load workflows_json/sample.json --run sample
  python main.py --load-dir workflows_json --list --status
  python main.py --load-dir workflows_json --run-pending --max-concurrent 3
        """
    )
    
    # T√πy ch·ªçn t·∫£i workflow
    parser.add_argument(
        '--load', '-l',
        type=str,
        help='T·∫£i m·ªôt workflow t·ª´ file JSON c·ª• th·ªÉ'
    )
    
    parser.add_argument(
        '--load-dir', '-d',
        type=str,
        default='workflows_json',
        help='T·∫£i t·∫•t c·∫£ workflow t·ª´ th∆∞ m·ª•c (m·∫∑c ƒë·ªãnh: workflows_json)'
    )
    
    # T√πy ch·ªçn th·ª±c thi
    parser.add_argument(
        '--run', '-r',
        type=str,
        help='Ch·∫°y m·ªôt workflow c·ª• th·ªÉ theo t√™n'
    )
    
    parser.add_argument(
        '--run-all', '-ra',
        action='store_true',
        help='Ch·∫°y t·∫•t c·∫£ workflow c√≥ th·ªÉ ch·∫°y ƒë∆∞·ª£c'
    )
    
    parser.add_argument(
        '--run-pending', '-rp',
        action='store_true',
        help='Ch·ªâ ch·∫°y c√°c workflow ·ªü tr·∫°ng th√°i Pending'
    )
    
    parser.add_argument(
        '--run-multiple', '-rm',
        type=str,
        nargs='+',
        help='Ch·∫°y nhi·ªÅu workflow c·ª• th·ªÉ (c√°ch nhau b·ªüi d·∫•u c√°ch)'
    )
    
    # T√πy ch·ªçn qu·∫£n l√Ω
    parser.add_argument(
        '--list', '-ls',
        action='store_true',
        help='Li·ªát k√™ t·∫•t c·∫£ workflow ƒë√£ t·∫£i'
    )
    
    parser.add_argument(
        '--status', '-s',
        action='store_true',
        help='Hi·ªÉn th·ªã tr·∫°ng th√°i t·ªïng quan c·ªßa WorkflowManager'
    )
    
    parser.add_argument(
        '--reset',
        type=str,
        help='Reset m·ªôt workflow v·ªÅ tr·∫°ng th√°i Pending'
    )
    
    parser.add_argument(
        '--reset-all',
        action='store_true',
        help='Reset t·∫•t c·∫£ workflow v·ªÅ tr·∫°ng th√°i Pending'
    )
    
    # T√πy ch·ªçn c·∫•u h√¨nh
    parser.add_argument(
        '--max-concurrent', '-mc',
        type=int,
        default=5,
        help='S·ªë workflow t·ªëi ƒëa ch·∫°y ƒë·ªìng th·ªùi (m·∫∑c ƒë·ªãnh: 5)'
    )
    
    parser.add_argument(
        '--use-proxy',
        action='store_true',
        help='S·ª≠ d·ª•ng proxy settings m·∫´u cho t·∫•t c·∫£ workflow'
    )
    
    parser.add_argument(
        '--headless',
        action='store_true',
        help='Ch·∫°y browser ·ªü ch·∫ø ƒë·ªô headless (·∫©n)'
    )

    args = parser.parse_args()
    
    # T·∫°o WorkflowManager
    print("üöÄ Kh·ªüi t·∫°o Workflow Manager...")
    manager = WorkflowManager(max_concurrent_workflows=args.max_concurrent)
    
    # Chu·∫©n b·ªã proxy settings
    proxy_settings = SAMPLE_PROXY_SETTINGS if args.use_proxy else None
    if proxy_settings:
        print("üåê S·ª≠ d·ª•ng proxy settings cho t·∫•t c·∫£ workflow")
    
    try:
        # T·∫£i workflow
        if args.load:
            # T·∫£i t·ª´ file c·ª• th·ªÉ
            workflow_path = Path(args.load)
            if not workflow_path.exists():
                print(f"‚ùå File kh√¥ng t·ªìn t·∫°i: {workflow_path}")
                return 1
            
            manager.load_workflow(workflow_path, proxy_settings)
            
        else:
            # T·∫£i t·ª´ th∆∞ m·ª•c
            workflows_dir = Path(args.load_dir)
            if workflows_dir.exists():
                manager.load_workflows_from_directory(workflows_dir, proxy_settings)
            else:
                print(f"‚ö†Ô∏è Th∆∞ m·ª•c kh√¥ng t·ªìn t·∫°i: {workflows_dir}")
                print("üí° T·∫°o th∆∞ m·ª•c v√† th√™m file JSON workflow ƒë·ªÉ b·∫Øt ƒë·∫ßu")
        
        # X·ª≠ l√Ω c√°c l·ªánh qu·∫£n l√Ω workflow
        if args.reset:
            if manager.reset_workflow(args.reset):
                print(f"‚úÖ ƒê√£ reset workflow: {args.reset}")
            return 0
        
        if args.reset_all:
            manager.reset_all_workflows()
            return 0
        
        # Hi·ªÉn th·ªã th√¥ng tin
        if args.list:
            workflows = manager.list_workflows()
            if workflows:
                print(f"\nüìã Danh s√°ch {len(workflows)} workflow:")
                for i, wf_info in enumerate(workflows, 1):
                    status_icon = {
                        'Pending': '‚è≥',
                        'Running': 'üîÑ', 
                        'Completed': '‚úÖ',
                        'Failed': '‚ùå'
                    }.get(wf_info['state'], '‚ùì')
                    
                    proxy_info = " (proxy)" if wf_info['has_proxy'] else ""
                    exec_time = f" [{wf_info['execution_time']:.2f}s]" if wf_info['execution_time'] else ""
                    
                    print(f"   {i:2d}. {status_icon} {wf_info['name']}: {wf_info['state']}{proxy_info}{exec_time}")
                    print(f"       Nodes: {wf_info['node_count']}, C√≥ th·ªÉ ch·∫°y: {'C√≥' if wf_info['can_run'] else 'Kh√¥ng'}")
            else:
                print("üì≠ Ch∆∞a c√≥ workflow n√†o ƒë∆∞·ª£c t·∫£i")
        
        if args.status:
            manager.print_status()
        
        # Th·ª±c thi workflow
        results = {}
        
        if args.run:
            # Ch·∫°y m·ªôt workflow c·ª• th·ªÉ
            result = await manager.run_workflow_by_name(args.run)
            results[args.run] = result
            
        elif args.run_multiple:
            # Ch·∫°y nhi·ªÅu workflow
            results = await manager.run_multiple_workflows(args.run_multiple)
            
        elif args.run_pending:
            # Ch·ªâ ch·∫°y workflow Pending
            results = await manager.run_all_pending_workflows()
            
        elif args.run_all:
            # Ch·∫°y t·∫•t c·∫£ workflow c√≥ th·ªÉ ch·∫°y
            results = await manager.run_all_runnable_workflows()
        
        # B√°o c√°o k·∫øt qu·∫£
        if results:
            print(f"\nüèÅ B√°o c√°o k·∫øt qu·∫£ th·ª±c thi:")
            successful = sum(1 for success in results.values() if success)
            total = len(results)
            
            for name, success in results.items():
                status = "‚úÖ Th√†nh c√¥ng" if success else "‚ùå Th·∫•t b·∫°i"
                print(f"   - {name}: {status}")
            
            print(f"\nüìä T·ªïng k·∫øt: {successful}/{total} workflow th√†nh c√¥ng")
            
            if successful < total:
                return 1  # C√≥ workflow th·∫•t b·∫°i
        
        # Hi·ªÉn th·ªã tr·∫°ng th√°i cu·ªëi
        if not args.list and not args.status and results:
            manager.print_status()
        
        return 0
        
    except KeyboardInterrupt:
        print("\n‚èπÔ∏è ƒê√£ d·ª´ng b·ªüi ng∆∞·ªùi d√πng")
        return 130
    
    except Exception as e:
        print(f"‚ùå L·ªói kh√¥ng mong ƒë·ª£i: {e}")
        return 1

def create_sample_workflow():
    """T·∫°o file workflow m·∫´u n·∫øu ch∆∞a t·ªìn t·∫°i."""
    workflows_dir = Path("workflows_json")
    sample_file = workflows_dir / "sample_workflow.json"
    
    if sample_file.exists():
        return
    
    workflows_dir.mkdir(exist_ok=True)
    
    sample_workflow = {
        "nodes": [
            {
                "id": "start_1",
                "type": "start",
                "x": 100,
                "y": 100,
                "params": {},
                "displayName": "B·∫Øt ƒë·∫ßu"
            },
            {
                "id": "goto_1", 
                "type": "goto",
                "x": 300,
                "y": 100,
                "params": {
                    "url": "https://example.com"
                },
                "displayName": "ƒêi·ªÅu h∆∞·ªõng ƒë·∫øn Example.com"
            },
            {
                "id": "wait_1",
                "type": "wait",
                "x": 500,
                "y": 100,
                "params": {
                    "timeout": 2000
                },
                "displayName": "Ch·ªù 2 gi√¢y"
            },
            {
                "id": "stop_1",
                "type": "stop",
                "x": 700,
                "y": 100,
                "params": {},
                "displayName": "K·∫øt th√∫c"
            }
        ],
        "connections": [
            {
                "fromNode": "start_1",
                "fromPort": "out", 
                "toNode": "goto_1",
                "toPort": "in"
            },
            {
                "fromNode": "goto_1",
                "fromPort": "out",
                "toNode": "wait_1",
                "toPort": "in"
            },
            {
                "fromNode": "wait_1",
                "fromPort": "out",
                "toNode": "stop_1",
                "toPort": "in"
            }
        ]
    }
    
    with open(sample_file, 'w', encoding='utf-8') as f:
        import json
        json.dump(sample_workflow, f, ensure_ascii=False, indent=2)
    
    print(f"üìù ƒê√£ t·∫°o workflow m·∫´u: {sample_file}")

if __name__ == "__main__":
    # T·∫°o workflow m·∫´u n·∫øu c·∫ßn
    create_sample_workflow()
    
    # Ch·∫°y ·ª©ng d·ª•ng ch√≠nh
    sys.exit(asyncio.run(main()))